---
output: pdf_document
---
```{r}
if (!require("plm")) install.packages("plm")
library(plm)

# I dowload my DataBase with read.csv2
DB_Tobin<-data.frame(read.csv2("DataBase/DB_Tobin.csv", sep = ";",stringsAsFactors=FALSE, header = TRUE ))
```


## Model 1

### Test

Analyse and test of my first model. These tests help select the panel model to be estimated. Here is my first model :

**Model 1 :** Green Initiatives on Tobin's Q

\begin{equation}
TobinsQ_{it+1}=\beta_{0} + \beta_{1} (SP_{it}) + \beta_{2} (ST_{it}) + \beta_{3} (AS_{it}) + \beta_{9} (C_{it}) + \varepsilon_{it}
\label{M1}
\end{equation}

#### Tests of poolability

Citation from [@Croissant2008] :

> *Pooltest tests the hypothesis that the same coefficients apply to each individual. It is a standard F test, based on the comparison of a model obtained for the full sample and a model based on the estimation of an equation for each individual. The first argument of pooltest is a plm object. The second argument is a pvcm object obtained with model=within. If the first argument is a pooling model, the test applies to all the coefficients (including the intercepts), if it is a within model, different intercepts are assumed.*

The null hypothesis of poolability assumes homogeneous slope coefficients.

When running this code I got this error : Error in FUN(X[[i]], ...) : insufficient number of observations
I still need to understand the origin.

```{r echo = FALSE, message = FALSE, error = FALSE}
# Test of poolability --> error that I cannot understand

# M1_pvcm <- pvcm(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + DebtRatio^2 + NetMargin + log(Asset), data=DB_Tobin, index=c("Companies", "YearFinancialIndicator"), model="within")

# M1_plm<-plm(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + DebtRatio^2 + NetMargin + log(Asset), data=DB_Tobin, model="within")

# pooltest(M1_pvcm,M1_plm)

# pooltest(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + DebtRatio^2 + NetMargin + log(Asset), data = DB_Tobin, index=c("Companies", "YearFinancialIndicator"), model = "within")
```

#### Fixed or Random : Hausman Test 

Citation from @Torres-Reyna2010 :

> *To decide between fixed or random effects you can run a Hausman test where the null hypothesis is that the preferred model is random effects vs. the alternative the fixed effects (see Green, 2008, chapter 9).  It basically tests whether the unique errors (ui) are correlated with the regressors, the null hypothesis is they are not.*


```{r}
fixed <- plm(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + DebtRatio^2 + NetMargin + log(Asset), data = DB_Tobin, index=c("Companies", "YearFinancialIndicator"), model = "within")

random <- plm(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + DebtRatio^2 + NetMargin + log(Asset), data = DB_Tobin, index=c("Companies", "YearFinancialIndicator"), model = "random")

phtest(fixed,random)
```

**Interpretation :** P-Value < 0.05 then Ho is rejected and I have to use the fixed-effect.


#### Testing for time fixed effects

```{r}
fixed <- plm(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + DebtRatio^2 + NetMargin + log(Asset), data = DB_Tobin, index=c("Companies", "YearFinancialIndicator"), model = "within")

fixed_time <- plm(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + DebtRatio^2 + NetMargin + log(Asset) + factor(YearFinancialIndicator), data = DB_Tobin, index=c("Companies", "YearFinancialIndicator"), model = "within")


# Testing the time-fixed effects. The null is that no time-fixed effects needed
pFtest(fixed_time, fixed)


```
**Interpretation Fixed_time effect :** P-Value is > 0.05 meaning that null hypothesis is verified and that there is not a significant time-fixed effect. **So I do not need to use time fixed effect in my model1!!**


#### Testing for cross-sectional dependence/contemporaneous correlation


Citation from @Torres-Reyna2010 :

> According to Baltagi, cross-sectional dependence is a problem in macro panels with long time series. This is not much of a problem in micro panels (few years and large number of cases). The null hypothesis in the B -P/LM and Pasaran CD tests of independence is that residuals across entities are not correlated. B-  P/LM and Pasaran CD (cross-sectional dependence) tests are used to test whether the residuals are correlated across entities*. Cross-sectional dependence can lead to bias in tests results (also called contemporaneous correlation). 


```{r}
pcdtest(fixed_time, test = c("lm"))
pcdtest(fixed_time, test = c("cd"))

pcdtest(fixed, test = c("lm"))
pcdtest(fixed, test = c("cd"))

```
Depending the method used, HO is verified (Pesaran), namely the model do not have cross-sectional dependence or rejected (Breusch-Pagan)... **Which one is the most suitable for my model?**


#### Testing for serial correlation

```{r}
pbgtest(fixed_time)
pbgtest(fixed)
```

**Interpretation:** HO is rejected as p-value < 0.05 then I have serial correlation....

#### Testing for stationarity

```{r}
if (!require("tseries")) install.packages("tseries")
library(tseries)
PanelSet <- plm.data(DB_Tobin, index = c("Companies", "YearFinancialIndicator"))
adf.test(PanelSet$TobinsQ, k=2)
```
Ho : Series has stationarity
**Interpretation :** p-value < 0.05 then ho is rejected and my panel data do not have stationarity


#### Testing for heteroskedasticity

```{r}
if (!require("lmtest")) install.packages("lmtest")
library(lmtest)

bptest(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + DebtRatio^2 + NetMargin + log(Asset) + factor(Companies), data = DB_Tobin, studentize = F)

```
**Interpretation: ** p-value < 0.05 then the null hypothesis of homoskedasticity is rejected and heteroskedasticity assumed... 


Use the **sandwich estimator** to account for the heteroskedasticity issue? See @MiroshnychenkoGreenpracticesfinancial2017 and @Stock2008

"If hetersokedaticity is detected you can use the sandwich estimaror" [@Torres-Reyna2010]

vcovHC is a function for estimating a robust covariance matrix of parameters for a fixed effects or random effects panel model according to the White method (White 1980, 1984; Arellano 1987). The --vcovHC– function estimates three heteroskedasticity-consistent covariance estimators:

* "white1" - for general heteroskedasticity but no serial correlation. Recommended for random effects.

* "white2" - is "white1" restricted to a common variance within groups. Recommended for random effects.

* "arellano" - both heteroskedasticity and serial correlation. Recommended for fixed effects.


The following options apply*:

* HC0 - heteroskedasticity consistent. The default.
* HC1,HC2, HC3 – Recommended for small samples. HC3 gives less weight to influential observations.
* HC4 - small samples with influential observations 
* HAC - heteroskedasticity and autocorrelation consistent (type ?vcovHAC for more details)


```{r}
coeftest(fixed) # Original coefficients 
coeftest(fixed, vcovHC) # Heteroskedasticity consistent coefficients
coeftest(fixed, vcovHC(fixed, method = "arellano")) # Heteroskedasticity consistent
coeftest(fixed, vcovHC(fixed, type = "HC3")) # Heteroskedasticity consistent coefficients, type 3coefficients (Arellano)
# The following shows the HC standard errors of the coefficients
t(sapply(c("HC0", "HC1", "HC2", "HC3", "HC4"), function(x) sqrt(diag(vcovHC(fixed, type = x)))))
```


**What should I do with those estimates?**
