---
output:
  pdf_document
header-includes:
- \usepackage{amsmath}
---
```{r echo =FALSE, message = FALSE, error = FALSE}
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)
if (!require("plm")) install.packages("plm")
library(plm)
if (!require("stargazer")) install.packages("stargazer")
library(stargazer)
# I download my database 

DB_Lag1<-data.frame(read.csv2("Analysis/DataBase/Lag_1.csv", sep = ";",stringsAsFactors=FALSE, header = TRUE ))

```

# Methodology {#Methodology}

## Econometric model

<!--
... Deal with methodology to test H1 ..... **To be defined**

-->


Panel data is a common approach to adress the CFP-CEP nexus [@Albertini2013]. Panel data, also called longitudinal data include observations on N cross section units (i.e., firms) over T time-periods [@Hsiao2007a]. @Bell2015 make a clear distinction between panel data and time-series cross-sectional (i.e. TSCS) data and highlights that the difference lies partly in its sample structure. TSCS data has comparatively few higher-level entities (usually groups of individuals such as countries, rather than individuals) and comparatively many measurement of time-periods [@Beck1995].

Panel data analysis using variation in both individuals and time dimensions is considered to be one of the most efficient analytical methods for data analysis[@DimitriosAsteriou2006]. It usually contains more degrees of freedom, less collinearity among the variables, more efficiency and more sample variability than one-dimensional method (i.e.cross-sectional data and time series data) giving a more accurate inference of the parameters estimated in the model [@Hsiao2007, @HsiaoChapitrePanelData2014]. @Roberts2013 also argued that using panel data offer a partial, but by no means complete and costless, solution to the problem of omitted variables in model, namely the most common causes of endogeneity in empirical corporate finance. Consequently this study use equation \ref{EconometricModel} to test the combined effect of process and outcome-based CEP on CFP (short term vs long term).

\begin{equation}
\centering
\begin{aligned}
Y_{it+1} & = & \beta_{0} + \beta_{1} (SPL_{it}) \\
&& + {} \beta_{2} (STC_{it}) + \beta_{3} (A_{it}) \\
&& + {} \beta_{4} (EnP_{it})  + \beta_{5} (CaP_{it}) \\
&& + {} \beta_{6} (WatP_{it}) + \beta_{7} (WastP_{it}) \\ 
&& + {} (Controls_{it}) + \varepsilon_{it}
\label{EconometricModel}
\end{aligned}
\end{equation}


where \(Y_{it+1}\) is a proxy of CFP measured as ROA (i.e. Model 1) or Tobin's Q (i.e. Model 2), \(SPL_{it}\) is a proxy for a firm's sustainability pay link, \(STC_{it}\) is a proxy for a firm's sustainability themed commitment, \(A_{it}\) is a proxy for a firm's audit score, \(EP_{it}\) is a proxy for a firm's energy productivity, \(CP_{it}\) is a proxy for a firm's carbon productivity, \(WatP_{it}\) is a proxy for a firm's water productivity, \(WasP_{it}\) is a proxy for a firm's waste productivity, \(Controls_{it}\) is a vector of control variables that includes firm size, industry sector, financial risk, R&D activities, advertising intensity and capital structure and lastly \(\varepsilon_{it}\) which is the error term.


**FE vs RE based on [@Bell2015] --> développez + appliquer sa méthode?**

Panel data setting implies that endogeneity occurs in cases where the independent variable in a regression model is correlated with the error term, or due to simultaneous causality between the dependent and the independent variable [@Sanchez-Ballesta2007, @Biorn2008, @Roberts2013]. Consequently, the presence of endogeneity implies that the fourth and fifth assumptions of OLS\footnote{Five assumptions are required to produce consistent estimators with OLS : (i) a random sample of observations on \(y\) and \((x_{1},...., x_{n})\), (ii) a mean zero error term, (iii) no linear relationship among the explanatory variables, (iv) an error term that is uncorrelated with each explanatory variables and (v) an error term with zero mean conditional on the explanatory variables.} are violated and scholars have to use a different method to produce consistent estimators [@Wooldridge2008, @Roberts2013]. Recent meta-analysis provided evidences that the CFP-CEP nexus is characterized by a bidirectional causality [@Orlitzky2001, @Orlitzky2003, @Wu2006, @Albertini2013, @Dixon-Fowler2013, @EndrikatMakingsenseconflicting2014, @Ludecadedebatenexus2014, @WangMetaAnalyticReviewCorporate2016, @Busch2018]. In order to adress potential endogeneity problems in my model, firstly, I have lagged observations in dependent and control variables one year behind financial performance. This method allows to increase the confidence of the direction of the relationship [@Hart1996, @Delmas2015, @MiroshnychenkoGreenpracticesfinancial2017] and *in fine* reduce the potential simultaneity bias. Secondly, given that the standard Hausman test had rejected the null hypothesis of random effect (see Annex... for results of the test or find a way to insert p-value in the table of regression idem for cross sectionnal dependence) I use a fixed effect model to regress the equation \ref{EconometricModel}. According to @Roberts2013, fixed effect model improve endogeneity concerns. 


```{r echo = FALSE, error = FALSE, message = FALSE, results = 'hide'}
if (!require("stargazer")) install.packages("stargazer")
library(stargazer)

if (!require("xtable")) install.packages("xtable")
library(xtable)

# Fixed Model

FixedTobinsQ <- plm(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + EnergyProductivity + CarbonProductivity + WaterProductivity + WasteProductivity + Leverage + NetMargin + FirmSize + Industry, data=DB_Lag1, index=c("Companies", "YearFinancialIndicator"), model="within")

FixedRoa <- plm(ROA ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + EnergyProductivity + CarbonProductivity + WaterProductivity + WasteProductivity + Leverage + NetMargin + FirmSize + Industry, data=DB_Lag1, index=c("Companies", "YearFinancialIndicator"), model="within")

# Random Model

RandomTobinsQ <- plm(TobinsQ ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + EnergyProductivity + CarbonProductivity + WaterProductivity + WasteProductivity + Leverage + NetMargin + FirmSize + Industry, data=DB_Lag1, index=c("Companies", "YearFinancialIndicator"), model="random")

RandomRoa <- plm(ROA ~ SustainabilityPayLink + SustainableThemedCommitment + AuditScore + EnergyProductivity + CarbonProductivity + WaterProductivity + WasteProductivity + Leverage + NetMargin + FirmSize + Industry, data=DB_Lag1, index=c("Companies", "YearFinancialIndicator"), model="random")

# Hausmann Test

PvalRoa <- round(phtest(FixedTobinsQ,RandomTobinsQ)$p.value, digits = 4)
HausmanTobinsQ <- cbind("Model 5",PvalRoa)

PvalTobinsQ <- round(phtest(FixedRoa,RandomRoa)$p.value, digits = 4)
HausmanRoa <- cbind("Model 6",PvalTobinsQ)


#summary in table

HausmanTable <- rbind(HausmanRoa, HausmanTobinsQ)
colnames(HausmanTable) <- c("Model","p-value")

#xtable(HausmanTable, caption = "Hausman Test Result", label = "Hausman", align = "rrr")

stargazer(HausmanTable, summary = FALSE, table.placement = "h", type="latex", label = "Hausman", title = "Hausman Test p-value", header = FALSE)

```


## Outliers treatment


@Lyu2015 defines outliers as observations in the dataset that appear to be unusual and discordant and which could lead to inconsistent results. @Osborne2004 have shown that even a small proportion of outliers can significantly affect simple analyses (i.e. t-tests, correlations and ANOVAs). Outliers are an issue only and only if they are influential \footnote{Influential obervations are observations whose  removal causes a different conclusion in the analysis} [@Cousineau2010]. I have used the Cook's distance [@Cook1977] test which is a common statistical tool to assess the influence of outliers [@JPStevens1984, @Cousineau2010, @Zuurprotocoldataexploration2010]. Cook’s Distance observe the difference between the regression paramater of a given model,  \(\hat{\beta}\) and what they become if the \(i_{th}\) data points is deleted,let's say  \(\hat{\beta}_{i}\). One difficulty with treatment of outliers is that the literature have not found common theoretical framework yet for the treatment of influential outliers [@OrrJohn1991, @Cousineau2010]. @Tabachnick2007 argue that the imputation with the mean is the best method while @Cousineau2010 highlights that it tends to reduce the spread of the population, make the observed distribution more leptokurtic, and possibly increase the likelihood of a type-I error. @Dang2009 argues that more elaborate technique involves replacing outliers with possible values while @Barnett1994 would prefere to remove or windsorized them. Alternatively, @Pollet2017 propose an other route to handle outliers and argue that inclusion or exclusion of outliers depend on the significativity of the results, meaning that if results are more significant without outliers, scholars should remove them and vice versa.

Following the mindset of @Pollet2017, I have concluded that model 1 using ROA as CFP proxies give better results with outliers and model 2 using Tobin's Q as CFP proxies give better results without outliers. See annex [outliers](#appendixA-outliers) for furthers details.




<!--
Motivations to use one time lag - citation from [@Albertini2013]: 

> Hart and Ahuja (1996) argue that there is a time lag between the initiation of emission reduction efforts and the realization of bottom line benefits. First, pollution prevention requires up-front investment in training and equipment. Second, it takes time to gain reduction because internal reorganization and renegotiation of supply and waste disposal contracts may be required (Hart & Ahuja, 1996). Evidence also suggests that in the early stages of pollution prevention there is a great deal of “low-hanging fruit”—easy and inexpensive behavioural and material changes that result in large emission reductions relative to costs (Hart, 1994; Rooney, 1993). As the firm’s environmental performance improves, further reductions in emissions become progressively more difficult, requiring more significant change in processes or even entirely new production technology (Russo & Fouts, 1997). Some studies have collected data on a longitudinal perspective (more than 1 year) in order to take into account the long-term payback of environmental management strategies, while others have collected data on a short period of time (1 year and less). Analysing the relationship between CEM and CFP during a short period of time implies that the researcher intends to prove that the environmental management influences regularly and at any time the financial profitability of the firm. Yet the natural and organizational environments are different because of the time markers of their respective materialities, such as short term for the financial profitability and very long term for the environmental issue (Bansal & Knox-Hayes, 2013). Thus, we can argue that the longitudinal characteristic of the studies might explain part of the variation in the results regarding the relationship between CEM and CFP. **NB: the hypothese had been verified : The relationship between CEM and CFP is significantly stronger for non-longitudinal studies (0.13) than for longitudinal studies (0.07)**

-->








## Sensitivity Analysis


Take ROE as another proxy of short term CFP. I need to find an other proxy for market-based indicator. I will also consider ESG factor of yahoo finance as a proxy for CEP.

To be continued...